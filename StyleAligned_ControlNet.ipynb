{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AXylRlBV_Zx",
        "outputId": "8583c893-942a-4076-dcdf-15cc53a4c99b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'StyleAlignedDiffModels'...\n",
            "remote: Enumerating objects: 389, done.\u001b[K\n",
            "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 389 (delta 59), reused 100 (delta 49), pack-reused 276\u001b[K\n",
            "Receiving objects: 100% (389/389), 106.35 MiB | 11.01 MiB/s, done.\n",
            "Resolving deltas: 100% (216/216), done.\n",
            "Updating files: 100% (30/30), done.\n",
            "/content/StyleAlignedDiffModels\n",
            "\u001b[0m\u001b[01;34mimgs\u001b[0m/      requirements.txt               StyleAligned_Explanation.ipynb        TO-DO.txt\n",
            "LICENSE    \u001b[01;34msrc\u001b[0m/                           StyleAligned_with_Prompts_only.ipynb\n",
            "README.md  StyleAligned_ControlNet.ipynb  StyleAligned_with_Reference.ipynb\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/alessioborgi/StyleAlignedDiffModels.git\n",
        "\n",
        "# Change directory to the cloned repository\n",
        "%cd StyleAlignedDiffModels\n",
        "%ls\n",
        "\n",
        "# Set up Git configuration\n",
        "!git config --global user.name \"Alessio Borgi\"\n",
        "!git config --global user.email \"alessioborgi3@gmail.com\"\n",
        "\n",
        "# Stage the changes\n",
        "#!git add .\n",
        "\n",
        "# Commit the changes\n",
        "#!git commit -m \"Added some content to your-file.txt\"\n",
        "\n",
        "# Push the changes (replace 'your-token' with your actual personal access token)\n",
        "#!git push origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2b06M0aV_Zz",
        "outputId": "641d93e2-13eb-4bd4-f328-c34dcb3e75dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "!pip install -r requirements.txt > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline, AutoencoderKL\n",
        "from diffusers.utils import load_image\n",
        "from transformers import DPTImageProcessor, DPTForDepthEstimation\n",
        "import torch\n",
        "import mediapy\n",
        "from src.Handler import Handler\n",
        "from src.StyleAlignedArgs import StyleAlignedArgs\n",
        "from src.ControlNet import SDXL_ControlNet_Model\n",
        "from src.Depth_Map import get_depth_map\n",
        "from src.HarrisCorner import get_edge_map "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the ControlNet model with specified parameters.\n",
        "ControlNet_Model = ControlNetModel.from_pretrained(\n",
        "    \"diffusers/controlnet-depth-sdxl-1.0\",  # Model identifier.\n",
        "    variant=\"fp16\",                         # Use 16-bit floating point precision.\n",
        "    use_safetensors=True,                   # Use SafeTensors for security.\n",
        "    torch_dtype=torch.float16               # Set Torch data type to float16.\n",
        ").to(\"cuda\")                                # Move model to GPU.\n",
        "\n",
        "# Load the AutoencoderKL model with specified parameters.\n",
        "AutoencoderKL_Model = AutoencoderKL.from_pretrained(\n",
        "    \"madebyollin/sdxl-vae-fp16-fix\",        # Model identifier.\n",
        "    torch_dtype=torch.float16               # Set Torch data type to float16.\n",
        ").to(\"cuda\")                                # Move model to GPU.\n",
        "\n",
        "# Initialize the Stable Diffusion XL ControlNet Pipeline\n",
        "SDXL_ControlNet_Pipeline = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",  # Model identifier.\n",
        "    controlnet=ControlNet_Model,                       # Attach the loaded ControlNet model.\n",
        "    vae=AutoencoderKL_Model,                                     # Attach the loaded AutoencoderKL model.\n",
        "    variant=\"fp16\",                              # Use 16-bit floating point precision.\n",
        "    use_safetensors=True,                        # Use SafeTensors for security.\n",
        "    torch_dtype=torch.float16                    # Set Torch data type to float16.\n",
        ").to(\"cuda\")                                     # Move pipeline to GPU.\n",
        "\n",
        "# Enable model CPU offload to optimize memory usage.\n",
        "SDXL_ControlNet_Pipeline.enable_model_cpu_offload()\n",
        "\n",
        "# Define Style Aligned Arguments with specified parameters.\n",
        "sa_args = StyleAlignedArgs(\n",
        "    share_group_norm=False,     # Do not share GroupNorm layers.\n",
        "    share_layer_norm=False,     # Do not share LayerNorm layers.\n",
        "    share_attention=True,       # Share Attention layers.\n",
        "    adain_queries=True,         # Apply Adaptive Instance Normalization to queries.\n",
        "    adain_keys=True,            # Apply Adaptive Instance Normalization to keys.\n",
        "    adain_values=False          # Do not apply Adaptive Instance Normalization to values.\n",
        ")\n",
        "\n",
        "# Initialize Handler with the pipeline.\n",
        "handler = Handler(SDXL_ControlNet_Pipeline)\n",
        "\n",
        "# Register the Style Aligned Arguments with the handler.\n",
        "handler.register(sa_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7.1: CONTROL-NET WITH SIMPLE IMAGE & STYLE-ALIGNMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and resize the control image to 1024x1024 pixels.\n",
        "control_image = load_image(\"./imgs/sun.png\").resize((1024, 1024))\n",
        "\n",
        "# Display the control image using mediapy.\n",
        "mediapy.show_image(control_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the reference style and prompts for the controlnet.\n",
        "reference_style_controlnet = \"flat design style\"\n",
        "reference_prompt = f\"a poster in {reference_style_controlnet}\"\n",
        "target_prompt = f\"the sun in {reference_style_controlnet}\"\n",
        "\n",
        "# Set the conditioning scale for controlnet.\n",
        "controlnet_conditioning_scale = 0.8\n",
        "\n",
        "# Specify the number of images to generate per prompt.\n",
        "num_images_per_prompt = 3  # Adjust according to VRAM at your disposal.\n",
        "\n",
        "# Generate random latents for the inference process.\n",
        "latents = torch.randn(1 + num_images_per_prompt, 4, 128, 128).to(SDXL_ControlNet_Pipeline.unet.dtype)\n",
        "latents[1:] = torch.randn(num_images_per_prompt, 4, 128, 128).to(SDXL_ControlNet_Pipeline.unet.dtype)\n",
        "\n",
        "# Call the controlnet pipeline to generate images based on the prompts and control image.\n",
        "images_generated = SDXL_ControlNet_Model(SDXL_ControlNet_Pipeline, [reference_prompt, target_prompt],\n",
        "                         image=control_image,\n",
        "                         num_inference_steps=50,\n",
        "                         controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
        "                         num_images_per_prompt=num_images_per_prompt,\n",
        "                         latents=latents)\n",
        "\n",
        "# Display the generated images along with the control image.\n",
        "mediapy.show_images(\n",
        "    [images_generated[0], control_image] + images_generated[1:],\n",
        "    titles=[\"reference\", \"depth\"] + [f'result {i}' for i in range(1, len(images_generated))]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7.2: CONTROL-NET WITH DEPTH MAP & STYLE-ALIGNMENT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the DPT model for depth estimation and move it to the GPU.\n",
        "DPT_Estimator = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-hybrid-midas\").to(\"cuda\")\n",
        "\n",
        "# Load the corresponding image processor for the DPT model.\n",
        "DPT_Feature_Processor = DPTImageProcessor.from_pretrained(\"Intel/dpt-hybrid-midas\")\n",
        "\n",
        "# Load the control image from the specified path.\n",
        "control_image = load_image(\"./imgs/train.png\")\n",
        "\n",
        "# Generate a depth map for the control image using the feature processor and depth estimator.\n",
        "control_depth_image = get_depth_map(control_image, DPT_Feature_Processor, DPT_Estimator)\n",
        "\n",
        "# Display the generated depth map using mediapy.\n",
        "mediapy.show_image(control_depth_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the reference style for ControlNet.\n",
        "reference_style_controlnet = \"flat design style\"\n",
        "\n",
        "# Create prompts for reference and target images.\n",
        "reference_prompt = f\"a poster in {reference_style_controlnet}\"  # Prompt for generating the reference image.\n",
        "target_prompt = f\"a train in {reference_style_controlnet}\"      # Prompt for generating the target image.\n",
        "\n",
        "# Set the conditioning scale for ControlNet.\n",
        "controlnet_conditioning_scale = 0.8\n",
        "\n",
        "# Specify the number of images to generate per prompt.\n",
        "num_images_per_prompt = 3  # Adjust according to VRAM size.\n",
        "\n",
        "# Generate random latents for the inference process.\n",
        "latents = torch.randn(1 + num_images_per_prompt, 4, 128, 128).to(SDXL_ControlNet_Pipeline.unet.dtype)\n",
        "latents[1:] = torch.randn(num_images_per_prompt, 4, 128, 128).to(SDXL_ControlNet_Pipeline.unet.dtype)\n",
        "\n",
        "# Call the ControlNet pipeline to generate images based on the prompts and control depth image.\n",
        "images = SDXL_ControlNet_Model(\n",
        "    SDXL_ControlNet_Pipeline,\n",
        "    [reference_prompt, target_prompt],  # Reference and target prompts.\n",
        "    image=control_depth_image,          # Control depth image input.\n",
        "    num_inference_steps=50,             # Number of inference steps.\n",
        "    controlnet_conditioning_scale=controlnet_conditioning_scale,  # Conditioning scale for ControlNet.\n",
        "    num_images_per_prompt=num_images_per_prompt,  # Number of images to generate per prompt.\n",
        "    latents=latents                     # Latents for the inference process.\n",
        ")\n",
        "\n",
        "# Display the generated images along with the control depth image.\n",
        "mediapy.show_images(\n",
        "    [images[0], control_depth_image] + images[1:],  # Reference image, control depth image, and other generated images.\n",
        "    titles=[\"reference\", \"depth\"] + [f'result {i}' for i in range(1, len(images))]  # Titles for each image.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7.3: CONTROL-NET WITH EDGE MAP (CANNY DETECTOR) & STYLE-ALIGNMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the DPT model for depth estimation and move it to the GPU.\n",
        "DPT_Estimator = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-hybrid-midas\").to(\"cuda\")\n",
        "\n",
        "# Load the corresponding image processor for the DPT model.\n",
        "DPT_Feature_Processor = DPTImageProcessor.from_pretrained(\"Intel/dpt-hybrid-midas\")\n",
        "\n",
        "# Load the control image from the specified path.\n",
        "control_image = load_image(\"./imgs/train.png\")\n",
        "\n",
        "# Generate edge map for the control image using the feature processor and depth estimator.\n",
        "control_edge_image = get_edge_map(control_image, DPT_Feature_Processor, DPT_Estimator)\n",
        "\n",
        "# Display the generated depth map using mediapy.\n",
        "mediapy.show_image(control_edge_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the reference style for ControlNet.\n",
        "reference_style_controlnet = \"flat design style\"\n",
        "\n",
        "# Create prompts for reference and target images.\n",
        "reference_prompt = f\"a poster in {reference_style_controlnet}\"  # Prompt for generating the reference image.\n",
        "target_prompt = f\"a train in {reference_style_controlnet}\"      # Prompt for generating the target image.\n",
        "\n",
        "# Set the conditioning scale for ControlNet.\n",
        "controlnet_conditioning_scale = 0.8\n",
        "\n",
        "# Specify the number of images to generate per prompt.\n",
        "num_images_per_prompt = 3  # Adjust according to VRAM size.\n",
        "\n",
        "# Generate random latents for the inference process.\n",
        "latents = torch.randn(1 + num_images_per_prompt, 4, 128, 128).to(SDXL_ControlNet_Pipeline.unet.dtype)\n",
        "latents[1:] = torch.randn(num_images_per_prompt, 4, 128, 128).to(SDXL_ControlNet_Pipeline.unet.dtype)\n",
        "\n",
        "# Call the ControlNet pipeline to generate images based on the prompts and control edge image.\n",
        "images = SDXL_ControlNet_Model(\n",
        "    SDXL_ControlNet_Pipeline,\n",
        "    [reference_prompt, target_prompt],  # Reference and target prompts.\n",
        "    image=control_edge_image,            # Control edge image input.\n",
        "    num_inference_steps=50,              # Number of inference steps.\n",
        "    controlnet_conditioning_scale=controlnet_conditioning_scale,  # Conditioning scale for ControlNet.\n",
        "    num_images_per_prompt=num_images_per_prompt,  # Number of images to generate per prompt.\n",
        "    latents=latents                     # Latents for the inference process.\n",
        ")\n",
        "\n",
        "# Display the generated images along with the control edge image.\n",
        "mediapy.show_images(\n",
        "    [images[0], control_edge_image] + images[1:],  # Reference image, control edge image, and other generated images.\n",
        "    titles=[\"reference\", \"edge\"] + [f'result {i}' for i in range(1, len(images))]  # Titles for each image.\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c0645f6e4d7492f83ef93f7fb221174": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_673157abc8994d54a280fea73c9e8214",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81c45fe35ead41b9a6c864e1a280320e",
            "value": 0
          }
        },
        "2c3662a126844552b4b2110e566d7f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ccdba0e0895413b82887364e200a846": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63febeeb3b724482a8c94923380806c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9ee7b08751b480cbed687f586284cfd",
              "IPY_MODEL_1c0645f6e4d7492f83ef93f7fb221174",
              "IPY_MODEL_bfe1a658b5d146a5a68e5f50879e0af7"
            ],
            "layout": "IPY_MODEL_cab2c7c32e454220ac3cb6c4e5c905e6"
          }
        },
        "673157abc8994d54a280fea73c9e8214": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8123d4c59c93469c98eccfad96e5de1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81c45fe35ead41b9a6c864e1a280320e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfe1a658b5d146a5a68e5f50879e0af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f44c2b3658e44c04970c7755b324249d",
            "placeholder": "​",
            "style": "IPY_MODEL_8123d4c59c93469c98eccfad96e5de1b",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "cab2c7c32e454220ac3cb6c4e5c905e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44c2b3658e44c04970c7755b324249d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ee7b08751b480cbed687f586284cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ccdba0e0895413b82887364e200a846",
            "placeholder": "​",
            "style": "IPY_MODEL_2c3662a126844552b4b2110e566d7f0f",
            "value": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
