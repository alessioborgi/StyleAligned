"""
Diffusion.py

This file contains the implementation of the Noise Prediction function to generate Latent Representations,
the Denoising Step function, and the whole DDIM Process.
Authors:
- Alessio Borgi (alessioborgi3@gmail.com)
- Francesco Danese (danese.1926188@studenti.uniroma1.it)

Created on: July 6, 2024
"""



from __future__ import annotations
import torch

from tqdm import tqdm
from typing import Callable
from diffusers import StableDiffusionXLPipeline

from .Tokenization_and_Embedding import embeddings_ensemble_with_neg_conditioning
from .Encode_Image import images_encoding_slerp
from .Diffusion import Generate_Noise_Prediction, Denoising_next_step, DDIM_Process, extract_latent_and_inversion
T = torch.tensor # Create Alias for torch.tensor to increase readability.
TN = T


# Defining a type alias for the Diffusion Inversion Process type of callable.
Diff_Inversion_Process_Callback = Callable[[StableDiffusionXLPipeline, int, T, dict[str, T]], dict[str, T]]


@torch.no_grad()
def DDIM_Inversion_Process(model: StableDiffusionXLPipeline, x0: list[np.ndarray], blending_weights: list[float], prompt: str, num_inference_steps: int, guidance_scale,) -> T:

    # 1) Encode Image: Encode the input image into a latent representation using the model's VAE.
    encoded_img = images_encoding_slerp(model, x0, blending_weights)

    # 2) Set Timesteps: Set the timesteps for the diffusion process.
    model.scheduler.set_timesteps(num_inference_steps, device=encoded_img.device)

    # 3) Perform DDIM Loop: Perform the DDIM denoising loop to generate a sequence of latent representations.
    latent_repr_sequence = DDIM_Process(model, encoded_img, prompt, guidance_scale)

    # 4) Return Sequence of Latents: Return the sequence of latent representations generated by the DDIM loop.
    return latent_repr_sequence
