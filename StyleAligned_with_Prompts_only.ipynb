{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STYLE-ALIGNED WITH PROMPTS ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/alessioborgi/StyleAlignedDiffModels.git\n",
    "\n",
    "# Change directory to the cloned repository\n",
    "%cd StyleAlignedDiffModels\n",
    "%ls\n",
    "\n",
    "# Set up Git configuration\n",
    "!git config --global user.name \"Alessio Borgi\"\n",
    "!git config --global user.email \"alessioborgi3@gmail.com\"\n",
    "\n",
    "# Stage the changes\n",
    "#!git add .\n",
    "\n",
    "# Commit the changes\n",
    "#!git commit -m \"Added some content to your-file.txt\"\n",
    "\n",
    "# Push the changes (replace 'your-token' with your actual personal access token)\n",
    "#!git push origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "!pip install -r requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import copy\n",
    "import torch\n",
    "import einops\n",
    "import mediapy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from typing import Any\n",
    "from typing import Callable\n",
    "from dataclasses import dataclass\n",
    "from diffusers.utils import load_image\n",
    "from torch.nn import functional as nnf\n",
    "from diffusers.models import attention_processor\n",
    "from diffusers.image_processor import PipelineImageInput\n",
    "from transformers import DPTImageProcessor, DPTForDepthEstimation\n",
    "from diffusers.utils.torch_utils import is_compiled_module, is_torch_version\n",
    "from diffusers import StableDiffusionXLPipeline, DDIMScheduler, ControlNetModel, StableDiffusionXLControlNetPipeline, AutoencoderKL\n",
    "\n",
    "import src.Handler as Handler\n",
    "import src.StyleAlignedArgs as StyleAlignedArgs\n",
    "\n",
    "T = torch.tensor # Create Alias for torch.tensor to increase readability.\n",
    "TN = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_linear = DDIMScheduler(\n",
    "    beta_start=0.00085,                 # Starting value of beta\n",
    "    beta_end=0.012,                     # Ending value of beta\n",
    "    beta_schedule=\"scaled_linear\",      # Type of schedule for beta values\n",
    "    clip_sample=False,                  # Whether to clip samples to a specified range\n",
    "    set_alpha_to_one=False,             # Whether to set alpha to one at the end of the process\n",
    "\n",
    "    num_train_timesteps=1000,           # Number of diffusion steps used during training\n",
    "    timestep_spacing=\"linspace\",        # Method to space out timesteps\n",
    "    prediction_type=\"epsilon\",          # Type of prediction model used in the scheduler\n",
    "    trained_betas=None                  # Optional pre-trained beta values\n",
    ")\n",
    "\n",
    "scheduler = scheduler_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDXL_Pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\",  # The model name or path\n",
    "    torch_dtype=torch.float16,            # Data type for the model's tensors\n",
    "    variant=\"fp16\",                       # Model variant for 16-bit floating point precision (Mixed Precision)\n",
    "    use_safetensors=True,                 # Use the safetensors library for safe tensor loading\n",
    "    scheduler=scheduler,                  # Scheduler instance for the diffusion process\n",
    "\n",
    "    revision=None,                        # Model version to use, default is None\n",
    "    use_auth_token=None,                  # Authentication token, None means no authentication\n",
    "    cache_dir=None,                       # Directory to cache the downloaded model, None uses default\n",
    "    force_download=False,                 # Force download even if the model exists locally\n",
    "    resume_download=False,                # Resume a partial download if available\n",
    "    proxies=None,                         # Dictionary of proxy servers to use, None means no proxies\n",
    "    local_files_only=False,               # Use only local files if set to True\n",
    "    device_map=None,                      # Device placement for model layers, None uses default placement\n",
    "    max_memory=None                       # Maximum memory allowed for each device, None means no specific limit\n",
    ").to(\"cuda\")                              # Move the model to the GPU for faster computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = Handler(SDXL_Pipeline)\n",
    "sa_args = StyleAlignedArgs(share_group_norm=False,\n",
    "                                      share_layer_norm=False,\n",
    "                                      share_attention=True,\n",
    "                                      adain_queries=True,\n",
    "                                      adain_keys=True,\n",
    "                                      adain_values=False\n",
    "                                     )\n",
    "\n",
    "handler.register(sa_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run StyleAligned\n",
    "\n",
    "sets_of_prompts = [\n",
    "  \"a toy train. macro photo. 3d game asset\",\n",
    "  \"a toy airplane. macro photo. 3d game asset\",\n",
    "  \"a toy car. macro photo. 3d game asset\",\n",
    "  \"a toy boat. macro photo. 3d game asset\",\n",
    "]\n",
    "images = SDXL_Pipeline(sets_of_prompts,).images\n",
    "mediapy.show_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run StyleAligned\n",
    "sets_of_prompts = [\n",
    "  \"a toy train. macro photo. 3d game asset\",\n",
    "  \"a toy airplane. macro photo. 3d game asset\",\n",
    "  \"a toy car. macro photo. 3d game asset\",\n",
    "]\n",
    "# sets_of_prompts = [\n",
    "#   \"a hot hair balloon, simple wooden statue\",\n",
    "#   \"a friendly robot, simple wooden statue\",\n",
    "#   \"a bull, simple wooden statue\",\n",
    "# ]\n",
    "images = []\n",
    "for prompt in sets_of_prompts:\n",
    "    # Generate image for each prompt individually\n",
    "    image = SDXL_Pipeline([prompt]).images[0]\n",
    "    images.append(image)\n",
    "    # Clear CUDA cache to free memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Print Memory summary\n",
    "    # print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "mediapy.show_images(images)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
